{"origin_pdf_path": "https://patpannuto.com/pubs/levy15ownership.pdf", "text_in_pdf": "Ownership is Theft: Experiences Building an Embedded OS in Rust\nAmit Levyy, Michael P Andersenz, Bradford Campbellx, David Cullerz,\nPrabal Duttax, Branden Ghenax, Philip Levisyand Pat Pannutox\nyStanford UniversityzUniversity of California, BerkeleyxUniversity of Michigan\n{levya,pal}@stanford.edu {m.andersen,culler}@berkeley.edu {bradjc,prabal,brghena,ppannuto}@umich.edu\nABSTRACT\nRust, a new systems programming language, provides compile-time\nmemory safety checks to help eliminate runtime bugs that manifest\nfrom improper memory management. This feature is advantageous\nfor operating system development, and especially for embedded\nOS development, where recovery and debugging are particularly\nchallenging. However, embedded platforms are highly event-based,\nand Rust’s memory safety mechanisms largely presume threads. In\nour experience developing an operating system for embedded sys-\ntems in Rust, we have found that Rust’s ownership model prevents\notherwise safe resource sharing common in the embedded domain,\nconﬂicts with the reality of hardware resources, and hinders using\nclosures for programming asynchronously. We describe these expe-\nriences and how they relate to memory safety as well as illustrate our\nworkarounds that preserve the safety guarantees to the largest extent\npossible. In addition, we draw from our experience to propose a new\nlanguage extension to Rust that would enable it to provide better\nmemory safety tools for event-driven platforms.\nCategories and Subject Descriptors\nD.3.3 [ Programming Languages ]: Language Constructs and Fea-\ntures; D.4.6 [ Operating Systems ]: Security and Protection\nGeneral Terms\nDesign, Security\nKeywords\nRust, Linear Types, Ownership, Embedded Operating Systems\n1. INTRODUCTION\nSafe languages promise to eliminate a large class of programming\nerrors at compile time. Safety is particularly appealing for an op-\nerating system kernel. Safety makes buffer and integer overﬂows,\nwhich constitute a signiﬁcant fraction of kernel bugs [7], impossible.\nStrongly typed languages can isolate different components of a sys-\ntem from each other at a ﬁner granularity than hardware protection\nmechanisms, which impose a high context switching overhead when\nused at a ﬁne grain (e.g., per device driver [12]).\nThe beneﬁts of language safety are especially attractive for an em-\nbedded operating system kernel, for three reasons. First, embedded\nPermission to make digital or hard copies of all or part of this work for\npersonal or classroom use is granted without fee provided that copies are not\nmade or distributed for proﬁt or commercial advantage and that copies bear\nthis notice and the full citation on the ﬁrst page. Copyrights for components\nof this work owned by others than the author(s) must be honored. Abstracting\nwith credit is permitted. To copy otherwise, or republish, to post on servers\nor to redistribute to lists, requires prior speciﬁc permission and/or a fee.\nRequest permissions from Permissions@acm.org.\nPLOS’15 , October 04-07 2015, Monterey, CA, USA\nCopyright is held by the owner/author(s). Publication rights licensed to\nACM.\nACM 978-1-4503-3942-1/15/10 ...$15.00\nDOI: http://dx.doi.org/10.1145/2818302.2818306.systems often use processors and microcontrollers that lack hard-\nware protection mechanisms such as memory management units:\nlanguage safety can protect software when hardware cannot. Second,\nembedded applications are less tolerant of crashes, as they cannot\nrely on user intervention to recover from runtime errors (e.g., restart\nthe application). Third, debugging embedded kernels is especially\ndifﬁcult because they often do not have logging features and require\nphysical access to attach a debugger. While safety does not prevent\nlogical errors or bugs, it does greatly protect an embedded kernel\nfrom hard crashes.\nUnfortunately, the downsides of additional features typical with\nsafe languages often outweigh these beneﬁts for systems program-\nming. Garbage collection, for example, introduces nondeterministic\ndelays. Automatic memory allocators complicate common kernel\noptimizations such as slab allocation [5].\nRust [2], a new, safe language designed for systems programming,\nincluding operating system kernels, promises memory safety with\nno runtime overhead. Rust differs from most safe languages in that\nit maintains safety and speed without having a garbage collector.\nIt relies heavily on compile-time checks that detect data races and\nunsafe memory accesses at no run-time overhead.\nWe have been using Rust to develop a new embedded operating\nsystem for microcontrollers called Tock. In particular, Tock targets\nembedded platforms with much less than a megabyte of memory—\nfor example, our development platform has 64KB of RAM. At ﬁrst\nexamination, Rust seems perfectly suited for this task. Rust achieves\nmemory and type safety without garbage collection by using a\nmechanism, derived from afﬁne types and unique pointers, called\nownership. However, in our experience so far, ownership semantics\nhave introduced new and unexpected challenges developing our\noperating system.\nIn our development efforts, we have encountered three problems\nwith using Rust to implement an embedded kernel. First, Rust’s\nautomatic memory management is not optimized for hardware re-\nsources and device drivers that are always present in the system.\nSecond, Rust’s ownership model prevents resource sharing between\nclosures and other kernel code, due to unnecessary thread safety\nconcerns in our setting. Finally, although closures are desirable for\nsimpliﬁed event handling, their requirement for dynamic memory is\nproblematic for embedded systems.\nWe describe each of these problems, illustrating examples where\nRust issues occur. We have been able to mostly workaround these\nissues. However, in many cases this came at the cost of incorporating\nmore of the operating system into the trusted computing base, which\nis allowed to circumvent the type system.\nTo better enable Rust to support event-driven embedded plat-\nforms, we explore a possible language feature we call execution\ncontexts . This feature would provide Rust with a valuable tool for al-\nlowing safe memory sharing when underlying hardware constraints\nor execution models can reliably prevent concurrency issues.\n2. RUST\nRust offers two important features that make it attractive as a\n\nlanguage for writing a secure, embedded operating system. First, it\npreserves type safety without relying on a runtime garbage collector\nfor memory management. Instead, Rust uses afﬁne types [14] to\ndetermine when memory can be freed at compile-time . Second, sim-\nilar to Modula-3 [6] and Haskell [13], Rust allows the programmer\nto explicitly separate code which is strictly bound to the type syste\nfrom code which may subvert it.\n2.1 Memory Management with Ownership\nMost safe languages achieve memory safety by using runtime\nchecks to determine when memory can safely be freed. Rust, instead,\navoids the runtime overhead by using the concept of ownership ,\ngenerally referred to as afﬁne types in the literature [14].\nEach value in Rust has a unique owner —namely, the variable to\nwhich it is bound. When the owner of a value goes out of scope, the\nvalue is freed. For example:\n{\nlet x = 43;\n}\nWithin the scope above, memory for the value 43is allocated and\nbound to the variable x. When the scope exits and xis no longer\naccessible its memory is reclaimed.\nBecause there can only be a single owner, aliasing is disallowed.\nInstead, values are either copied (if the type of the value implements\ntheCopy trait) or moved between variables. Once a value is moved,\nit is no longer accessible from the original variable binding. For\nexample, the following code is not permissible:\n{\nlet x = Foo::new();\nlet y = x;\nprintln(\"{}\", x);\n}\nBecause Foo::new() has been moved from xtoy,xis no\nlonger valid. Similarly, moving a value into a function by passing\nit as an argument invalidates the original variable. As a result,\nfunctions must explicitly hand ownership back to the caller:\nfnbar(x: Foo) -> Foo {\n// do something useful with ‘x‘\nx// <- return x\n}\nlet my_x = Foo;\nlet my_x = bar(my_x);\nTo simplify programming, Rust allows references to a value,\ncalled borrows , without invalidating the original variable. Borrows\nare created using an &and can be either mutable or immutable.\nThere are two main restrictions on borrows:\n1.A value can only be mutably borrowed if there are no other\nborrows of the value.\n2.Borrows cannot outlive the value they borrow. This prevents\ndangling pointer bugs.\nThis ownership model allows the compiler to provide two impor-\ntant safety mechanisms. First, it allows the compiler to determine\nwhen to free dynamically allocated memory from the stack or heap.\nMemory bugs like double-free and use-after-free are impossible in\nthis model. Second, it eliminates many data races by preventing\nconcurrent access to resources by multiple threads.\nIn many systems, this ownership model works well. For example,\nin a threaded network server, resources such as client requests are\nlogically isolated from each other and can be owned by a singlethread. When multiple threads need to share a resource, they can\npass ownership through channels. However, as we discuss in the rest\nof this paper, it does not work well in systems that use non thread-\nbased concurrency models and when resources must be shared.\n2.2 The unsafe Keyword\nRust has an explicit separation between trusted code, which can\ncircumvent the type system in certain ways, from untrusted code,\nwhich is strictly bound to the type system. Speciﬁcally, trusted\ncode can use blocks wrapped in the unsafe to perform unsafe\noperations (e.g. dereference a raw pointer) or call other unsafe\nfunctions.\nTheunsafe keyword can be used in two ways. First, any block\nof code can be wrapped in an unsafe block to allow it to perform op-\nerations that might break the type system. For example, a hardware\nabstraction layer can use this feature to expose a memory-mapped\nI/O register as a normal Rust struct:\nlet mydevice : & mut IORegs = unsafe {\n&mut (0x200103F asmut IORegs)\n}\nSecond, functions can be annotated with unsafe which prevents\nuntrusted code from calling them. For example, the standard li-\nbrary’s transmute function casts its input into any other type of\nthe same size:\npub unsafe fn transmute(e: T) -> U\nPackages compiled with -F unsafe_code cannot use the\nunsafe keyword, allowing systems builders to isolate trusted code\non a per package basis. An operating system fundamentally must\nperform certain operations which violate the type system. For ex-\nample, hardware is often conﬁgured through memory mapped I/O\nregisters which must be cast into usable data structures from ar-\nbitrary pointers. This mechanism allows the operating system to\nseparate between trusted modules which must, for example, address\nhardware directly, and untrusted modules like device drivers which\nshould access hardware through a narrower interfaces. When devel-\noping a secure system, the challange lies in minimizing the amount\nof code that uses unsafe language features.\n3. CHALLENGES\nResource constrained microcontrollers face challenges in terms\nof energy use, memory availability, and execution time that uniquely\nshape the operating system design.\nIn particular, embedded operating systems must be more reliable\nand use less memory than their general-purpose counterparts. For\nexample, the platform which Tock targets has only 64KB of memory.\nMost embedded platforms do not typically exceed 256KB of RAM,\nand most have signiﬁcantly less. As a result, embedded operating\nsystems avoid memory intensive mechanisms like threading, and\ninstead opt for event driven concurrency [10].\nSimilarly, microcontrollers generally do not have hardware mem-\nory management units and cannot support virtual memory. As a\nresult, they avoid dynamic memory mechanisms both because swap-\nping memory to gracefully degrade upon memory exhaustion is not\npossible, and because dynamic allocations may be explicitly prohib-\nited (e.g. for MISRA C [11] compliance). Conversely, average case\nperformance is not generally a bottleneck, so embedded operating\nsystems can trade CPU cycles to save memory or provide safety.\nReliability is paramount for embedded operating systems due to\nthe difﬁculty of debugging and lack of human interaction. Lever-\naging the compile time guarantees of a safe language to isolate\nkernel extensions can help make the operating system more reli-\nable without restricting ﬂexibility. The SPIN [4] operating system,\n\nfor example, was written in Modula-3. SPIN showed how a safe\nlanguage provides safe, fast access to protected kernel resources.\nThis safe access, in turn, enables applications to safely extend the\nkernel with new features and services. Having similar safe extensi-\nbility is extremely valuable in an embedded kernel, because a kernel\nmust be able to adapt to many custom hardware conﬁgurations and\napplications.\nImplementing an operating system for an embedded platform in\nRust, which is nominally well suited for these limitations as it is a\nlow-level language that provides memory safety, has raised three\nmain issues: the tension between ownership and cyclic dependencies\nin an operating system, capturing state in callback closures, and\nstatically allocating closure memory.\n3.1 Resource Ownership\nRust’s memory ownership model, while providing useful memory-\nmanagement tools, can conﬂict with common scenarios that arise\nin operating systems. First, many operating system resources are\nnot dynamically allocated. For example, hardware peripherals are\nalways present, and device drivers are allocated once at system\ninitialization. As these resources are never freed, the ownership\nmechanisms do not need to manage the lifetimes of these resources.\nSecond, resources must often be shared between multiple logical\nunits. For example, consider a simple networked application where\na reference to the networking stack must be shared between a UDP\ninterface (to allow applications to send packets) and the underlying\nradio driver (to allow the radio hardware to notify that packets have\nbeen received).\n// Both UDP and RadioDriver need a reference to the\n// networking stack.\nimpl UDP {\n// Called from an application to send a packet. Must be able\n// to tell the networking stack to transmit a new packet.\nfnsend(& mut self, packet) {\nself.network_stack.outgoing(packet);\n}\n}\nimpl RadioDriver {\n// Called from the main loop when a packet arrives.\n// on_receive needs a reference to network_stack\n// to notify it of a received packet.\nfnon_receive(& mut self, packet) {\nself.network_stack.incoming(packet);\n}\n}\nIn order to avoid possible data races, Rust’s ownership model does\nnot allow the UDP interface and RadioDriver to keep references\nto the networking stack simultaneously. While hardware interrupts\nare asynchronous, and therefore run concurrently with other kernel\ncode, in our operating system interrupt handlers enqueue tasks to\nbe run in the main scheduler loop, which is single-threaded. As a\nresult, on_receive andsend can never run concurrently and no\ndata race is possible.\nWe overcome both issues by declaring most resources as static\nvariables and borrowing them with ’static lifetime. In Rust,\nborrows with ’static lifetimes are treated specially: only unsafe\ncode can create such a borrow, but once created they can be re-\nborrowed mutably any number of times. Intuitively, the ’static\nlifetime points to the “original sin” of borrowing a static variable\nunsafely. Therefore, none of the safety semantics that apply to\nnormal borrows are applied to those with static lifetimes.\nBeing able to mutably borrow static variables multiple times\nmeans our operating system can allow multiple drivers to referencehardware resources or each other. However, doing so means we lose\nthe ability to detect real data races at compile time, for example,\nif the kernel passes a shared resource to an interrupt handler that\nmay run concurrently. Instead, we resort to an overly conservative\nconvention in which interrupt handlers perform no work except\nposting to the main scheduler’s task queue. An ideal mechanism\nwould, instead, allow for shared state between components that will\nnever run concurrently, but disallow sharing when they may.\n3.2 Callbacks through Closures\nEmbedded operating systems are largely event-driven: most com-\nputation happens in response to events—e.g. a timer ﬁring, an\nI/O operation completing, or an external interrupt triggering. The\nstandard C approach to event-driven code is to pass a callback func-\ntion pointer as a parameter to an asynchronous call. When the\nasynchronous operation completes, it invokes the callback. There\nare two problems with this approach. First, a linear sequence of\nasynchronous operations does not appear in a linear piece of code.\nInstead, it is spread across a series of many small functions. Sec-\nond, the programmer must manually pass state between callers and\ncallbacks, e.g., by using “stack ripping” [3].\nEvent-driven application languages, such as JavaScript, help solve\nthis problem by allowing callbacks to be speciﬁed as closures at the\ncall site:\nvar count = 0;\nsetInterval( function () {\nconsole.log(count + \" clicks\");\n}, 2000);\nonClick( function () {\ncount += 1;\n});\nThe ability write to the callback at the point it is registered makes\nreading asynchronous code easier. Furthermore, the ability to close\nover variables from the caller makes resource management simpler.\nHowever, this programming approach requires closure to capture\nshared state to avoid stack ripping. In the example above, when the\ncall to onClick returns, there are three valid handles to count :\none in the caller, and one in each of the closures. In the case of\nJavaScript, this is safe: programs are single-threaded, so the callback\ncannot access the closure while the calling context executes.\nRust has closures, but does not assume a particular threading\nmodel, so its ownership system prohibits a similar construction. For\nthe closure to capture a variable, it must either take ownership of it,\npreventing the caller from accessing it, or complete before returning\nto the caller.\nlet mut x = 0;\nsetInterval( move \" indicates a closure in Rust\nprintln!(\"{} clicks\", x);\n}, 2000);\n// x is no longer valid in this context, and we\n// cannot create the closure for onClick\nIn the context of an embedded OS, this can be critically limiting.\nIn practice, this leads software to take one of two approaches, neither\ndesirable. The ﬁrst carefully partitions state between a caller and\ncallbacks. For example, instead of using a single, intuitive variable\nfor the LEDs on a device that allows all of the lights to be controlled:\n// No other code can access LEDs\nsetTimeout( {\nleds.activityToggle();\n}, 2000);\nthe ownership concerns force the code to partition the LEDs so that\naccess to each one is stored in separate variables.\n\nsetTimeout( {\nactivityLed.toggle();\n}, 2000);\nUnfortunately, the end result of partitioning is tiny, ﬁne-grained\ninterfaces that are very hard to manage. A callback that needs\nto toggle multiple LEDs, for example, needs to capture each one\nseparately in the closure.\nThe second approach is to avoid compile time ownership checks\nand rely on run-time mechanisms. While this may work for some\napplications, it defeats the purpose of leveraging compile-time safety\nchecks for an embedded operating system.\n3.3 Closure Memory Management\nSince closures capture dynamic variables, and several instances\nof a closure may be outstanding concurrently, closures are typically\nallocated dynamically. However, embedded operating systems often\ndo not, or cannot support dynamic memory allocation.\nOn the other hand, several common asynchronous patterns do not\nrequire closures to be re-entrant, and the memory for the closure\ncan instead be statically allocated at the call site. For example, in\nTinyOS [10], a callback is either posted or not—posting it multiple\ntimes results in a single invocation. In Rust, it makes sense to\nexpress this with closures:\nfnset_lcd(text: [ u8; 256], on_done: &F) {\nspi_write(START, to_static( {\nspi_write(text, onDone);\n})\n);\n}\nTheset_lcd function writes a START sequence to the SPI bus\nconnected to an LCD screen, followed by the text to display on the\nscreen. Multiple outstanding closures will never exist as another\nSPI command cannot be executed until the current command is\ncompleted. The goal of to_static in the example above is to\ncopy captured values into a statically allocated memory buffer (in\nthis case the text buffer and a pointer to the on_done callback).\nBut how would we implement to_static ?\nIn Rust, each closure has a unique type. Therefore, the following\nto_static signature would result in a separate instantiation of\nthe function for each closure passed to it:\nfnto_static(closure: F) -> &F\nIn principal, this would allow us to statically allocate a buffer\nsized for each particular closure. Unfortunately, there is no size_of\nkeyword in Rust, and static initialization cannot invoke functions—\nin this case the function size_of() -> usize provided\nby the Rust core library. In comparions, it is possible to write a\nversion of to_static in C++11, which has lambdas with similar\nsemantics to Rust closures, as well as asize_of keyword that is\nresolved at compile-time.\nWhile the syntactic additions required to support statically allo-\ncating closures in Rust would be small, they would have a profound\ndifference for engineering resource constrained systems. In our\nembedded operating system, we have had to abandon closures as a\ncallback mechanism, in favor of more cumbersome, and less com-\nprehensible styles such as statically binding callbacks and manual\nstack ripping.\n4. PROPOSED LANGUAGE MECHANISM:\nEXECUTION CONTEXTS\nThe core issue underlying hardware resource sharing and callback\nclosures is that Rust does not allow mutable aliasing. This helpsprevent common bugs such as data races between threads, iterator\ninvalidation etc. However, under certain constraints, for example,\nif all aliases are used fromthe same thread, mutable aliases might\nbe perfectly safe. This is the common case for embedded systems,\nwhich typically have only one primary execution thread occasionally\npunctuated by interrupt handlers. Currently, however, Rust’s type\nsystem is not rich enough to express constraints on thread execution.\nWe propose an extension to the Rust type-system, called execution\ncontexts , that reﬂects the thread of a value’s owner in its type. We\nargue that this type information could be used to allow multiple\nborrows of a value from within the same thread, but not across\nthreads. Execution contexts are a compile-time only mechanism\nthat allow the compiler to identify safe operations.\nTo deﬁne an execution context, type parameters are preﬁxed with\nthe hash character ( #), akin to current lifetime annotations ( ’). A\nvalue’s execution context is determined by its owner. When a value\nis moved between threads (e.g. through a channel), it takes on\nthe execution context of its new owner. Borrows have a borrowed\nexecution context (in addition to their own execution context as\nvalues) that reﬂects the execution context of the value they borrow.\nFinally, execution contexts can be instantiated as type parameters\nin functions and trait implementations. For example, closure traits\n(e.g., FnMut ,FnOnce ) have an execution context parameter that\ndetermines the context in which they run. Table 1 summarizes the\ndifferent types that may include an execution context. While every\nreference has an execution context, like lifetimes they can be elided\nin most cases.\nValue #a val\nBorrow & #a var\nClosure Trait FnOnce\nFunction Parameter fnf(var: & #a T) -> #a ()\nTable 1: Execution context usage. An execution context ais repre-\nsented in the type system as #a. Execution contexts can be attached\nto values, borrows, and closure traits, and can also be used as pa-\nrameters in functions.\n4.1 Semantics of Execution Contexts\nThe goal of execution contexts is to allow programs to mutably\nborrow values multiple times as long as those borrows are never\nshared between threads. Execution contexts allow the compiler to\ndistinguish such sharing from actual errors using only local analysis.\nBy deﬁnition, the whole execution of a scope must run in one\nexecution context. Thus every value owned in that scope must have\nthe same execution context. Because callers must own the return\nvalue of their callees, values in a parent and a child scope must have\nthe same execution context. Therefore, a thread (a single call-graph\nwith no internal concurrency) maps to an execution context.\nEntry functions (e.g. main orextern functions such as signal or\nhardware interrupt handlers) begin a new execution context. Func-\ntions can also “create” new execution contexts by forcing closures to\nrun in a different execution context than the return value of the func-\ntion. For example, the spawn function from the standard library,\nwhich runs its argument in a new POSIX thread:\nfnspawn(func: F) -> #a ()\nwhere F: FnOnce() + #b;\n// Does not compile: Cannot borrow across contexts\nlet x = 0;\nspawn( { println!(\"In thread: {}\", x); });\n// Does compile: Can take sole ownership with move\n\nlet x = 0;\nspawn( move  { println!(\"In thread: {}\", x); });\nThe return value of spawn has execution context #a, meaning\nthe caller of spawn has that execution context. Conversely, the\nargument to spawn is a closure that runs with execution context #b.\nBecause #amight not equal #b, the closure cannot borrow values\nfrom the caller, protecting against possible race conditions.\nBorrowed execution contexts reﬂect the original value’s execution\ncontext and do not change when the borrow is moved. Furthermore,\nbecause a value cannot be moved while there are borrows of it, a\nborrowed execution context always matches the execution context\nof the original value. While borrows, themselves, can be moved\nbetween threads, they can only be dereferenced from an execution\ncontext that matches their borrowed execution context. Importantly,\nthis allows borrows to be stored as ﬁelds in data structures that might\nbe moved between threads, while preserving thread safety.\nExecution contexts permit code that was always safe but previ-\nously invalid in Rust. Consider a ballot box that stores votes as a list\nof closures to run when votes are tallied:1\nstruct BallotBox {\nvotes: LinkedList() + ’a>>,\nyays: #a u32\n}\nimpl  BallotBox {\npub fn vote_yay(&’b #a mut self) -> #a () {\nvotes.push_back(\nHeapPtr::alloc( {self.yays += 1})\n)\n}\npub fn tally(& #a mut self) -> #a u32 {\nfor f in self.votes.iter_mut() {\nf();\n}\nreturn self.yays;\n}\n}\nThe stored closures each hold a mutable reference to self with the\nsame execution context ( #a) as constrained by the type parameter\ninitialization from the impl statement. Since the closures are run\nto completion in the same thread, these multiple borrows do not\nintroduce race conditions.\nIn some cases, it is necessary to permit multiple execution con-\ntexts to access the same values. Figure 1 shows how an interrupt\nhandler, which executes in a unique handler context ( #h), can post a\ntask to a shared queue that the scheduler, executing the main kernel\ncontext ( #k), can dequeue and run. This example introduces the last\nnew construct: the #any execution context. Any execution context\nmay access a value with the #any . Accesses must be serialized\ninternally, for example, using mutexes or atomic sections (disabling\ninterrupts) as appropriate.\n4.2 Limitations\nMulti-threaded execution is not the only issue that arises from\nmutable aliasing. For example, internal references union types may\nbreak the type system if different types may point to overlapping\nmemory [1]. Similarly, dynamically sized data structures such as\nvectors must not free data that may still be referenced by a different\nalias. Therefore, supporting mutable aliasing in Rust might require\nsubtle changes to the standard library. While we believe execution\ncontexts can, in general, be safe, we have not fully explored their\nimplications on the wider Rust ecosystem.\n1We use HeapPtr types to allocate heap memory. Readers familiar\nwith Rust should read these as Rust’s Box type.// InterruptQueue is shared between threads. It is marked with\n// the #any context to signify that it can be mutably borrowed\n// from any thread. The enqueue and dequeue methods must\n// be implemented using atomic blocks for safety\nlet interrupt_queue: #any InterruptQueue =\nInterruptQueue::new();\nstruct ButtonDriver {\ncount: #k usize\n}\nimpl  ButtonDriver {\npub fn handle_interrupt(& #k mut self) {\n// Because self is borrowed with thread #k, we know\n// the caller is in the same thread that owns self.count,\n// and are able to borrow it mutably. In our case, this is\n// because ‘handle_interrupt’ was called from main\nself.count += 1;\n}\npub fn RAW_INTERRUPT(& #h mut self) {\n// Cannot borrow self.counter because it belongs to\n// context #k and not #h. Instead self is enqueued to\n// be handled from the main thread\ninterrupt_queue.enqueue(self);\n}\n}\nfnmain() {\nlet button_driver = ButtonDriver{count: 0};\nloop {\ninterrupt_queue.dequeue().handle_interrupt();\n}\n}\nFigure 1: Complete example of execution contexts. An\ninterrupt_queue is shared between a lightweight “top-half”\ninterrupt handler that runs in the interrupt context and the (naïve)\nscheduler that executes the majority of the interrupt logic in the\n“bottom-half” interrupt handler in the main kernel execution context.\n5. RELATED WORK AND CONCLUSIONS\nSeveral previous operating systems have used language features\nto guarantee the safety of kernel components. SPIN [4] allows appli-\ncations to download extensions written in Modula-3 into the kernel,\nand uses the language to sandbox the extensions. Singularity [9]\nrequires that applications as well as the entire kernel are written in a\nmanaged language (C#) and relies entirely on a language sandbox\n(rather than hardware protection) to isolate applications. Unlike\nSingularity, Tock cannot rely on a garbage collected language due\nto the constraints of embedded systems. TinyOS [10] detects data\nraces between threads at compile time and requires the programmer\nto wrap accesses to shared data in atomic blocks that temporarily\ndisable interrupts. However, TinyOS uses a superset of nesC (a C\ndialect) which provides no memory or type safety.\nClarke and Wrigstad [8] point out a similar issue arising from\nborrowing unique types in a closed loop. They propose the notion\nofexternal uniqueness , which allows an object subgraph to contain\ncyclic internal references while having a unique external owner.\nOur proposal for execution contexts in Rust is similar but considers\nexecution threads, instead of object graphs, as the unit of isolation.\nRust’s low-level interface, safe memory management, and large\ncommunity make it a particularly good ﬁt for operating system\ndevelopment. If future language development can address the chal-\nlenges we have demonstrated, Rust should be well positioned to\nsupport the next generation of correct embedded operating systems.\n6. REFERENCES\n[1] Rust issue: \"borrowck is unsound in the presence of &’static\n\nmuts\". https://github.com/rust-lang/rust/\nissues/27616 .\n[2] The Rust programming language.\nhttp://www.rust-lang.org .\n[3] A DYA, A., H OWELL , J., T HEIMER , M., B OLOSKY , W. J.,\nAND DOUCEUR , J. R. Cooperative task management without\nmanual stack management. In Proceedings of the General\nTrack of the Annual Conference on USENIX Annual Technical\nConference (Berkeley, CA, USA, 2002), ATEC ’02, USENIX\nAssociation, pp. 289–302.\n[4] B ERSHAD , B. N., C HAMBERS , C., E GGERS , S., M AEDA ,\nC., M CNAMEE , D., P ARDYAK , P., S AVAGE , S., AND SIRER ,\nE. G. Spin–an extensible microkernel for application-speciﬁc\noperating system services. ACM SIGOPS Operating Systems\nReview 29 , 1 (1995), 74–77.\n[5] B ONWICK , J., ET AL . The slab allocator: An object-caching\nkernel memory allocator. In USENIX summer (1994), vol. 16,\nBoston, MA, USA.\n[6] C ARDELLI , L., D ONAHUE , J., J ORDAN , M., K ALSOW , B.,\nAND NELSON , G. The modula– type system. In Proceedings\nof the 16th ACM SIGPLAN-SIGACT Symposium on Principles\nof Programming Languages (New York, NY , USA, 1989),\nPOPL ’89, ACM, pp. 202–212.\n[7] C HEN, H., M AO, Y., W ANG , X., Z HOU , D., Z ELDOVICH ,\nN., AND KAASHOEK , M. F. Linux kernel vulnerabilities:\nState-of-the-art defenses and open problems. In Proceedings\nof the Second Asia-Paciﬁc Workshop on Systems (2011),\nACM, p. 5.\n[8] C LARKE , D., AND WRIGSTAD , T. External uniqueness is\nunique enough. ECOOP 2003–Object-Oriented Programming\n(2003), 59–67.\n[9]HUNT, G. C., AND LARUS , J. R. Singularity: Rethinking the\nsoftware stack. ACM SIGOPS Operating Systems Review 41 ,\n2 (April 2007), 37–49.\n[10] L EVIS , P., M ADDEN , S., P OLASTRE , J., S ZEWCZYK , R.,\nWHITEHOUSE , K., W OO, A., G AY, D., H ILL, J., W ELSH ,\nM., B REWER , E., AND CULLER , D. TinyOS: An operating\nsystem for sensor networks. In Ambient Intelligence ,\nW. Weber, J. Rabaey, and E. Aarts, Eds. Springer Berlin\nHeidelberg, 2005, pp. 115–148.\n[11] M OTOR INDUSTRY SOFTWARE RELIABILITY\nASSOCIATION ,ET AL .MISRA-C: 2012: Guidelines for the\nUse of the C Language in Critical Systems . MIRA, 2013.\n[12] S WIFT , M. M., M ARTIN , S., L EVY, H. M., AND EGGERS ,\nS. J. Nooks: An architecture for reliable device drivers. In\nProceedings of the 10th workshop on ACM SIGOPS European\nworkshop (2002), ACM, pp. 102–107.\n[13] T EREI , D., M ARLOW , S., P EYTON JONES , S., AND\nMAZIÈRES , D. Safe haskell. In Proceedings of the 2012\nHaskell Symposium (New York, NY , USA, 2012), Haskell ’12,\nACM, pp. 137–148.\n[14] T OV, J. A., AND PUCELLA , R. Practical afﬁne types. In\nProceedings of the 38th Annual ACM SIGPLAN-SIGACT\nSymposium on Principles of Programming Languages (New\nYork, NY , USA, 2011), POPL ’11, ACM, pp. 447–458.", "files_in_pdf": []}